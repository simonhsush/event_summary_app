# app.py
import streamlit as st
from datetime import datetime, timedelta
import pandas as pd
import io
import re
from dateutil import parser as dateparser
import docx
from docx import Document
from docx.enum.text import WD_COLOR_INDEX

st.set_page_config(page_title="æ–‡ä»¶æ—¥æœŸç¯©é¸æ‘˜è¦å™¨", layout="wide")
st.title("ðŸ“„ Word æ–‡ä»¶ â€” æ‰¾å‡ºå«æŒ‡å®šæ—¥æœŸçš„æ¬„ä½ä¸¦ç”¢ç”Ÿæ‘˜è¦æª”")

st.markdown(
    """
ä¸Šå‚³ `.docx`ï¼ˆå¯å«è¡¨æ ¼æˆ–æ®µè½ï¼‰ï¼Œé¸æ“‡ï¼š
- ä½¿ç”¨ã€Œå‰ä¸€å€‹å·¥ä½œæ—¥ï¼ˆå‰ä¸€å€‹ç‡Ÿæ¥­æ—¥ï¼‰ã€æˆ–è¼¸å…¥**æŒ‡å®šæ—¥æœŸ**ï¼Œ
- é¸æ“‡è¦æ¯”å°çš„æ¬„ä½åç¨±ï¼ˆè‹¥ Word å…§ç‚ºè¡¨æ ¼æœƒåˆ—å‡ºæ¬„ä½ä¾›é¸ï¼‰ï¼Œ
ç¨‹å¼æœƒæ‰¾å‡ºåœ¨è©²æ¬„ä½å…§å«æœ‰ç›®æ¨™æ—¥æœŸï¼ˆæˆ–æ—¥æœŸå­—ä¸²ï¼‰çš„åˆ—ï¼Œä¸¦ç”¢ç”Ÿæ‘˜è¦æª”ä¸‹è¼‰ã€‚
"""
)

# -----------------------
# æ—¥æœŸè™•ç†é‚è¼¯ï¼ˆä¿ç•™åŽŸæ¨£ï¼‰
# -----------------------
def prev_business_day(ref_date=None):
    if ref_date is None:
        ref = datetime.now()
    else:
        ref = ref_date
    one = timedelta(days=1)
    d = ref - one
    while d.weekday() >= 5:
        d -= one
    return d.date()

date_regex = re.compile(
    r'(?:(?:\d{4}[/-]\d{1,2}[/-]\d{1,2})|(?:\d{1,2}[/-]\d{1,2}[/-]\d{2,4})|(?:\d{1,2}[\u4e00-\u9fff]{1}\d{1,2}[\u4e00-\u9fff]{0,1}\d{0,2}))'
)

def extract_tables_to_dfs(doc):
    dfs = []
    for t in doc.tables:
        rows = []
        for r in t.rows:
            cleaned_cells = [re.sub(r'[\u200b\r\n\t]+', '', c.text.strip()) for c in r.cells]
            rows.append(cleaned_cells)

        if len(rows) < 2:
            continue

        # --- æ ¸å¿ƒä¿®æ³•ï¼šæ‰¾å‡ºã€Œæœ€æœ‰å¯èƒ½æ˜¯æ¨™é¡Œåˆ—ã€çš„é‚£ä¸€åˆ— ---
        # è¦å‰‡ï¼š
        # 1ï¸âƒ£ å«æœ€å¤šéžç©ºæ ¼æ–‡å­—çš„åˆ—
        # 2ï¸âƒ£ æ¬„ä½æ•¸èˆ‡ä¸‹ä¸€åˆ—æŽ¥è¿‘
        header_candidates = [(i, sum(1 for c in r if c.strip()), len(r)) for i, r in enumerate(rows)]
        header_candidates = sorted(header_candidates, key=lambda x: (-x[1], -x[2]))
        header_row_idx = header_candidates[0][0]

        header = rows[header_row_idx]
        data = rows[header_row_idx + 1:]

        # æ¬„ä½è£œé½Š
        max_len = max(len(r) for r in data) if data else len(header)
        header = header + [""] * (max_len - len(header))
        data = [r + [""] * (max_len - len(r)) for r in data]

        try:
            df = pd.DataFrame(data, columns=header)
        except Exception:
            df = pd.DataFrame(data)

        dfs.append(df)

    return dfs


def find_date_like_in_text(text):
    found = []
    for m in date_regex.findall(text):
        s = m
        try:
            dt = dateparser.parse(s, dayfirst=False, fuzzy=True)
            if dt:
                found.append(dt.date())
        except Exception:
            continue
    return found

# -----------------------
# ðŸ”¹ å¼·åŒ–æ—¥æœŸæ¯”å°é‚è¼¯ï¼ˆæ”¯æ´ 10/23ã€114/10/23ã€10_23ã€10æœˆ23æ—¥ï¼‰
# -----------------------
def filter_df_by_date_in_column(df, column, target_date):
    if column not in df.columns:
        return pd.DataFrame()
    matches = []
    for idx, cell in df[column].fillna("").items():
        text = str(cell)

        # ðŸ”¹ å°‡åº•ç·šèˆ‡å…¨å½¢ç¬¦è™Ÿæ­£è¦åŒ–
        normalized_text = (
            text
            .replace("ï¼", "/")
            .replace("ï¼", "-")
            .replace("_", "/")
            .replace("ï¼Ž", ".")
        )

        # ðŸ”¹ åŽŸé‚è¼¯ + æ“´å……æ ¼å¼
        td_strs = [
            target_date.strftime("%Y-%m-%d"),
            target_date.strftime("%Y/%m/%d"),
            target_date.strftime("%Y%m%d"),
            target_date.strftime("%m/%d"),
            f"{target_date.month}/{target_date.day}", # â† ç„¡å¹´ä»½
        ]

        td_chinese = f"{target_date.year}å¹´{target_date.month}æœˆ{target_date.day}æ—¥"
        td_chinese_short = f"{target_date.month}æœˆ{target_date.day}æ—¥" # â† ä¸­æ–‡çŸ­æ ¼å¼
        td_roc = f"{target_date.year - 1911}/{target_date.month}/{target_date.day}" # â† æ°‘åœ‹å¹´æ ¼å¼
        td_roc_no_year = f"{target_date.month}/{target_date.day}" # â† æ°‘åœ‹å¹´çœç•¥æƒ…æ³

        found = False
        # ðŸ”¹ æ”¹åœ¨ normalized_text è£¡æ‰¾
        if any(s in normalized_text for s in td_strs) or \
           td_chinese in normalized_text or \
           td_chinese_short in normalized_text or \
           td_roc in normalized_text or \
           td_roc_no_year in normalized_text:
            found = True
        else:
            parsed = find_date_like_in_text(normalized_text)
            if parsed and any(d == target_date for d in parsed):
                found = True

        if found:
            matches.append((idx, cell))

    if not matches:
        return pd.DataFrame()
    return df.loc[[idx for idx, _ in matches]]


# -----------------------
# åŒ¯å‡º Word â€” å¾žæ—¥æœŸå¾Œå–æŒ‡å®šå­—æ•¸
# -----------------------
def export_to_word(data, target_date_str, num_chars, filename="æ‘˜è¦è¼¸å‡º.docx"):
    doc = Document()
    doc.add_heading("æœå°‹æ‘˜è¦çµæžœ", level=1)
    doc.add_paragraph(f"æœå°‹æ—¥æœŸé—œéµå­—ï¼š{target_date_str}")
    doc.add_paragraph(" ")

    if "text" not in data.columns:
        data = data.copy()
        data["text"] = data.apply(lambda r: " ".join([str(x) for x in r.values if pd.notna(x)]), axis=1)

    for idx, row in data.iterrows():
        src = row.get("_source_table", "")
        col = row.get("_matched_column", "")
        snippet = str(row.get("text", "")).strip()

        p = doc.add_paragraph(f"{idx+1}. ä¾†æº: {src}, æ¬„ä½: {col}\n")
        if snippet:
            run = p.add_run(snippet)
            run.font.highlight_color = WD_COLOR_INDEX.YELLOW
        else:
            p.add_run("(æœªæ‰¾åˆ°å¯æ“·å–çš„æ®µè½)")
        doc.add_paragraph("----")

    doc.save(filename)
    return filename


# -----------------------
# Streamlit UI
# -----------------------
uploaded_file = st.file_uploader("ä¸Šå‚³ Word (.docx) æª”æ¡ˆ", type=["docx"])
st.write("ï¼ˆæª”æ¡ˆå…§å®¹åªåœ¨æœ¬æ¬¡åŸ·è¡Œä¸­è™•ç†ï¼Œä¸æœƒä¸Šå‚³åˆ°ä»»ä½•å¤–éƒ¨ä¼ºæœå™¨ï¼‰")

num_chars = st.number_input("è«‹è¼¸å…¥è¦æ“·å–çš„å­—æ•¸ï¼ˆå¾žæ—¥æœŸå­—ä¸²ä¹‹å¾Œé–‹å§‹è¨ˆç®—ï¼Œé è¨­20ï¼‰", min_value=1, max_value=1000, value=20)

col1, col2 = st.columns([2, 1])
with col1:
    date_mode = st.radio("é¸æ“‡ç›®æ¨™æ—¥æœŸï¼š", ("å‰ä¸€å€‹å·¥ä½œæ—¥", "è¼¸å…¥æŒ‡å®šæ—¥æœŸ (YYYY-MM-DD)"))
    if date_mode == "è¼¸å…¥æŒ‡å®šæ—¥æœŸ (YYYY-MM-DD)":
        user_date_str = st.text_input("æŒ‡å®šæ—¥æœŸ (ä¾‹: 2025-10-22)", value="")
        try:
            user_date = dateparser.parse(user_date_str).date() if user_date_str.strip() else None
        except Exception:
            user_date = None
    else:
        user_date = None

with col2:
    st.write("é€²éšŽé¸é …")
    prefer_table = st.checkbox("å„ªå…ˆå¾žè¡¨æ ¼æ¬„ä½ç¯©é¸ (è‹¥æª”æ¡ˆå«è¡¨æ ¼å‰‡åˆ—å‡ºæ¬„ä½)", value=True)
    download_format = st.selectbox("ä¸‹è¼‰æ‘˜è¦æ ¼å¼", ["CSV", "ç´”æ–‡å­— (TXT)", "Word (.docx)"])

# -----------------------
# ä¸»æµç¨‹
# -----------------------
if uploaded_file is not None:
    try:
        doc = docx.Document(uploaded_file)
    except Exception as e:
        st.error(f"ç„¡æ³•è®€å– Word æª”ï¼š{e}")
        st.stop()

    if date_mode == "å‰ä¸€å€‹å·¥ä½œæ—¥":
        target_date = prev_business_day()
        target_date_str = target_date.isoformat()
    else:
        if user_date is None:
            st.warning("è«‹è¼¸å…¥æœ‰æ•ˆçš„æŒ‡å®šæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰ã€‚")
            st.stop()
        target_date = user_date
        target_date_str = str(target_date)

    st.info(f"å°‡æ¯”å°çš„ç›®æ¨™æ—¥æœŸï¼š {target_date_str}")

    dfs = extract_tables_to_dfs(doc)
    result_rows = []

    if dfs and prefer_table:
        st.write(f"åµæ¸¬åˆ° {len(dfs)} å€‹è¡¨æ ¼ï¼Œæ­£åœ¨æŽƒæè¡¨æ ¼æ¬„ä½...")
        all_cols = set()
        for df in dfs:
            all_cols.update(list(df.columns))
        all_cols = [c for c in all_cols if str(c).strip() != ""]
        if all_cols:
            chosen_cols = st.multiselect("é¸æ“‡è¦æ¯”å°çš„æ¬„ä½ï¼ˆè¡¨æ ¼æ¬„ä½ï¼‰", options=all_cols, default=all_cols[:2])
        else:
            chosen_cols = []
        if chosen_cols:
            for i, df in enumerate(dfs):
                df = df.astype(str)
                for col in chosen_cols:
                    filtered = filter_df_by_date_in_column(df, col, target_date)
                    if not filtered.empty:
                        filtered = filtered.copy()
                        snippets = []
                        for _, r in filtered.iterrows():
                            cell_text = str(r[col])
                            td_candidates = [
                                target_date.strftime("%Y-%m-%d"),
                                target_date.strftime("%Y/%m/%d"),
                                f"{target_date.year}å¹´{target_date.month}æœˆ{target_date.day}æ—¥"
                            ]
                            start_idx = -1
                            chosen_td = None
                            for td in td_candidates:
                                if td in cell_text:
                                    start_idx = cell_text.find(td)
                                    chosen_td = td
                                    break
                            if start_idx != -1:
                                end_idx = min(len(cell_text), start_idx + len(chosen_td) + num_chars)
                                snippet = cell_text[start_idx:end_idx]
                            else:
                                snippet = ""
                            snippets.append(snippet)
                        filtered = filtered.reset_index(drop=True)
                        filtered["text"] = snippets
                        filtered["_source_table"] = f"table_{i+1}"
                        filtered["_matched_column"] = col
                        filtered = filtered[filtered["text"].str.strip() != ""]
                        if not filtered.empty:
                            result_rows.append(filtered)

    if not result_rows:
        st.write("å¾žæ®µè½ä¸­æœå°‹å«æœ‰ç›®æ¨™æ—¥æœŸçš„æ–‡å­—...")
        paragraphs = [p.text.strip() for p in doc.paragraphs if p.text.strip()]
        para_matches = []

        for i, txt in enumerate(paragraphs):
            parsed = find_date_like_in_text(txt)
            if parsed and any(d == target_date for d in parsed):
                td_candidates = [
                    target_date.strftime("%Y-%m-%d"),
                    target_date.strftime("%Y/%m/%d"),
                    f"{target_date.year}å¹´{target_date.month}æœˆ{target_date.day}æ—¥"
                ]
                start_idx = -1
                chosen_td = None
                for td in td_candidates:
                    if td in txt:
                        start_idx = txt.find(td)
                        chosen_td = td
                        break
                if start_idx != -1:
                    end_idx = min(len(txt), start_idx + len(chosen_td) + num_chars)
                    snippet = txt[start_idx:end_idx]
                    para_matches.append((i, snippet))

        if para_matches:
            dfp = pd.DataFrame(para_matches, columns=["para_index", "text"])
            dfp["_source_table"] = "paragraphs"
            dfp["_matched_column"] = "text"
            result_rows.append(dfp)

    if result_rows:
        final = pd.concat(result_rows, ignore_index=True, sort=False)
        final = final[final["text"].astype(str).str.strip() != ""].reset_index(drop=True)

        st.subheader("æ‰¾åˆ°çš„çµæžœç¯„ä¾‹ï¼ˆå‰ 200 åˆ—ï¼‰")
        st.dataframe(final.head(200))
        st.write(f"å…±æ‰¾åˆ° {len(final)} ç­†ç¬¦åˆç›®æ¨™æ—¥æœŸ ({target_date_str}) çš„é …ç›®ã€‚")

        if download_format == "CSV":
            towrite = io.StringIO()
            final.to_csv(towrite, index=False, encoding="utf-8-sig")
            st.download_button(
                "ä¸‹è¼‰ CSV æª”ï¼ˆUTF-8-SIGï¼‰",
                data=towrite.getvalue().encode("utf-8-sig"),
                file_name=f"summary_{target_date_str}.csv",
                mime="text/csv"
            )
        elif download_format == "ç´”æ–‡å­— (TXT)":
            txt_buf = io.StringIO()
            for i, row in final.iterrows():
                txt_buf.write(f"ä¾†æº: {row.get('_source_table','')}, æ¬„ä½: {row.get('_matched_column','')}\n")
                txt_buf.write(f"{row.get('text','')}\n")
                txt_buf.write("----\n")
            st.download_button(
                "ä¸‹è¼‰ TXT æª”",
                data=txt_buf.getvalue().encode("utf-8"),
                file_name=f"summary_{target_date_str}.txt",
                mime="text/plain"
            )
        elif download_format == "Word (.docx)":
            export_to_word(final, target_date_str, num_chars, filename="æ—¥æœŸæ®µè½æ‘˜è¦.docx")
            out_doc = docx.Document("æ—¥æœŸæ®µè½æ‘˜è¦.docx")
            word_stream = io.BytesIO()
            out_doc.save(word_stream)
            word_stream.seek(0)
            st.download_button(
                "ä¸‹è¼‰ Word æ‘˜è¦æª”",
                data=word_stream,
                file_name=f"summary_{target_date_str}.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
    else:
        st.warning("æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„é …ç›®ã€‚è«‹ç¢ºèªï¼š\n- Word æ˜¯å¦å«æœ‰è¡¨æ ¼æˆ–æ®µè½ä¸­æ˜¯å¦æœ‰æ—¥æœŸå­—ä¸²ã€‚\n- è‹¥æ—¥æœŸæ ¼å¼ç‰¹æ®Šï¼Œå¯å˜—è©¦æ‰‹å‹•è¼¸å…¥ç²¾ç¢ºæ—¥æœŸå­—ä¸²ä½œç‚ºæ¯”å°æ¢ä»¶ã€‚")





