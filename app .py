# app.py
import streamlit as st
from datetime import datetime, timedelta
import pandas as pd
import io
import re
from dateutil import parser as dateparser
import docx
from docx import Document
from docx.enum.text import WD_COLOR_INDEX

st.set_page_config(page_title="æ–‡ä»¶æ—¥æœŸç¯©é¸æ‘˜è¦å™¨", layout="wide")
st.title("ğŸ“„ Word æ–‡ä»¶ â€” æ‰¾å‡ºå«æŒ‡å®šæ—¥æœŸçš„æ¬„ä½ä¸¦ç”¢ç”Ÿæ‘˜è¦æª”")

st.markdown(
    """
ä¸Šå‚³ `.docx`ï¼ˆå¯å«è¡¨æ ¼æˆ–æ®µè½ï¼‰ï¼Œé¸æ“‡ï¼š
- ä½¿ç”¨ã€Œå‰ä¸€å€‹å·¥ä½œæ—¥ï¼ˆå‰ä¸€å€‹ç‡Ÿæ¥­æ—¥ï¼‰ã€æˆ–è¼¸å…¥**æŒ‡å®šæ—¥æœŸ**ï¼Œ
- é¸æ“‡è¦æ¯”å°çš„æ¬„ä½åç¨±ï¼ˆè‹¥ Word å…§ç‚ºè¡¨æ ¼æœƒåˆ—å‡ºæ¬„ä½ä¾›é¸ï¼‰ï¼Œ
ç¨‹å¼æœƒæ‰¾å‡ºåœ¨è©²æ¬„ä½å…§å«æœ‰ç›®æ¨™æ—¥æœŸï¼ˆæˆ–æ—¥æœŸå­—ä¸²ï¼‰çš„åˆ—ï¼Œä¸¦ç”¢ç”Ÿæ‘˜è¦æª”ä¸‹è¼‰ã€‚
"""
)

# -----------------------
# æ—¥æœŸè™•ç†é‚è¼¯ï¼ˆä¿ç•™åŸæ¨£ï¼‰
# -----------------------
def prev_business_day(ref_date=None):
    if ref_date is None:
        ref = datetime.now()
    else:
        ref = ref_date
    one = timedelta(days=1)
    d = ref - one
    while d.weekday() >= 5:
        d -= one
    return d.date()

date_regex = re.compile(
    r'(?:(?:\d{4}[/-]\d{1,2}[/-]\d{1,2})|(?:\d{1,2}[/-]\d{1,2}[/-]\d{2,4})|(?:\d{1,2}[\u4e00-\u9fff]{1}\d{1,2}[\u4e00-\u9fff]{0,1}\d{0,2}))'
)

def extract_tables_to_dfs(doc):
    dfs = []
    for t in doc.tables:
        rows = []
        for r in t.rows:
            rows.append([c.text.strip() for c in r.cells])
        if len(rows) >= 2:
            header = rows[0]
            data = rows[1:]
            try:
                df = pd.DataFrame(data, columns=header)
            except Exception:
                df = pd.DataFrame(data)
        else:
            df = pd.DataFrame(rows)
        dfs.append(df)
    return dfs

def find_date_like_in_text(text):
    found = []
    for m in date_regex.findall(text):
        s = m
        try:
            dt = dateparser.parse(s, dayfirst=False, fuzzy=True)
            if dt:
                found.append(dt.date())
        except Exception:
            continue
    return found

# -----------------------
# ğŸ”¹ å¼·åŒ–æ—¥æœŸæ¯”å°é‚è¼¯ï¼ˆæ”¯æ´ 10/23ã€114/10/23ã€10_23ã€10æœˆ23æ—¥ï¼‰
# -----------------------
def filter_df_by_date_in_column(df, column, target_date):
    if column not in df.columns:
        return pd.DataFrame()
    matches = []
    for idx, cell in df[column].fillna("").items():
        text = str(cell)

        # ğŸ”¹ å°‡åº•ç·šèˆ‡å…¨å½¢ç¬¦è™Ÿæ­£è¦åŒ–
        normalized_text = (
            text
            .replace("ï¼", "/")
            .replace("ï¼", "-")
            .replace("_", "/")
            .replace("ï¼", ".")
        )

        # ğŸ”¹ åŸé‚è¼¯ + æ“´å……æ ¼å¼
        td_strs = [
            target_date.strftime("%Y-%m-%d"),
            target_date.strftime("%Y/%m/%d"),
            target_date.strftime("%Y%m%d"),
            target_date.strftime("%m/%d"),
            f"{target_date.month}/{target_date.day}", # â† ç„¡å¹´ä»½
        ]

        td_chinese = f"{target_date.year}å¹´{target_date.month}æœˆ{target_date.day}æ—¥"
        td_chinese_short = f"{target_date.month}æœˆ{target_date.day}æ—¥" # â† ä¸­æ–‡çŸ­æ ¼å¼
        td_roc = f"{target_date.year - 1911}/{target_date.month}/{target_date.day}" # â† æ°‘åœ‹å¹´æ ¼å¼
        td_roc_no_year = f"{target_date.month}/{target_date.day}" # â† æ°‘åœ‹å¹´çœç•¥æƒ…æ³

        found = False
        # ğŸ”¹ æ”¹åœ¨ normalized_text è£¡æ‰¾
        if any(s in normalized_text for s in td_strs) or \
           td_chinese in normalized_text or \
           td_chinese_short in normalized_text or \
           td_roc in normalized_text or \
           td_roc_no_year in normalized_text:
            found = True
        else:
            parsed = find_date_like_in_text(normalized_text)
            if parsed and any(d == target_date for d in parsed):
                found = True

        if found:
            matches.append((idx, cell))

    if not matches:
        return pd.DataFrame()
    return df.loc[[idx for idx, _ in matches]]


# -----------------------
# åŒ¯å‡º Word â€” å¾æ—¥æœŸå¾Œå–æŒ‡å®šå­—æ•¸
# -----------------------
def export_to_word(data, target_date_str, num_chars, filename="æ‘˜è¦è¼¸å‡º.docx"):
    doc = Document()
    doc.add_heading("æœå°‹æ‘˜è¦çµæœ", level=1)
    doc.add_paragraph(f"æœå°‹æ—¥æœŸé—œéµå­—ï¼š{target_date_str}")
    doc.add_paragraph(" ")

    if "text" not in data.columns:
        data = data.copy()
        data["text"] = data.apply(lambda r: " ".join([str(x) for x in r.values if pd.notna(x)]), axis=1)

    for idx, row in enumerate(data["text"].astype(str).tolist(), start=1):
        text = row
        start_idx = text.find(target_date_str)
        if start_idx == -1:
            try:
                parts = re.findall(r'(\d{4})[-/](\d{1,2})[-/](\d{1,2})', target_date_str)
                if parts:
                    y, m, d = parts[0]
                    chinese = f"{int(y)}å¹´{int(m)}æœˆ{int(d)}æ—¥"
                    start_idx = text.find(chinese)
                    target_for_slice = chinese
                else:
                    target_for_slice = target_date_str
            except Exception:
                target_for_slice = target_date_str
        else:
            target_for_slice = target_date_str

        if start_idx != -1:
            slice_start = start_idx
            slice_end = min(len(text), slice_start + len(target_for_slice) + num_chars)
            snippet = text[slice_start:slice_end]
        else:
            snippet = ""

        p = doc.add_paragraph(f"{idx}. ")
        if snippet:
            run = p.add_run(snippet)
            run.font.highlight_color = WD_COLOR_INDEX.YELLOW
        else:
            p.add_run("(æœªæ‰¾åˆ°å¯æ“·å–çš„æ®µè½)")

    doc.save(filename)
    return filename


# -----------------------
# Streamlit UI
# -----------------------
uploaded_file = st.file_uploader("ä¸Šå‚³ Word (.docx) æª”æ¡ˆ", type=["docx"])
st.write("ï¼ˆæª”æ¡ˆå…§å®¹åªåœ¨æœ¬æ¬¡åŸ·è¡Œä¸­è™•ç†ï¼Œä¸æœƒä¸Šå‚³åˆ°ä»»ä½•å¤–éƒ¨ä¼ºæœå™¨ï¼‰")

num_chars = st.number_input("è«‹è¼¸å…¥è¦æ“·å–çš„å­—æ•¸ï¼ˆå¾æ—¥æœŸå­—ä¸²ä¹‹å¾Œé–‹å§‹è¨ˆç®—ï¼Œé è¨­20ï¼‰", min_value=1, max_value=1000, value=20)

col1, col2 = st.columns([2, 1])
with col1:
    date_mode = st.radio("é¸æ“‡ç›®æ¨™æ—¥æœŸï¼š", ("å‰ä¸€å€‹å·¥ä½œæ—¥", "è¼¸å…¥æŒ‡å®šæ—¥æœŸ (YYYY-MM-DD)"))
    if date_mode == "è¼¸å…¥æŒ‡å®šæ—¥æœŸ (YYYY-MM-DD)":
        user_date_str = st.text_input("æŒ‡å®šæ—¥æœŸ (ä¾‹: 2025-10-22)", value="")
        try:
            user_date = dateparser.parse(user_date_str).date() if user_date_str.strip() else None
        except Exception:
            user_date = None
    else:
        user_date = None

with col2:
    st.write("é€²éšé¸é …")
    prefer_table = st.checkbox("å„ªå…ˆå¾è¡¨æ ¼æ¬„ä½ç¯©é¸ (è‹¥æª”æ¡ˆå«è¡¨æ ¼å‰‡åˆ—å‡ºæ¬„ä½)", value=True)
    download_format = st.selectbox("ä¸‹è¼‰æ‘˜è¦æ ¼å¼", ["CSV", "ç´”æ–‡å­— (TXT)", "Word (.docx)"])

# -----------------------
# ä¸»æµç¨‹
# -----------------------
if uploaded_file is not None:
    try:
        doc = docx.Document(uploaded_file)
    except Exception as e:
        st.error(f"ç„¡æ³•è®€å– Word æª”ï¼š{e}")
        st.stop()

    if date_mode == "å‰ä¸€å€‹å·¥ä½œæ—¥":
        target_date = prev_business_day()
        target_date_str = target_date.isoformat()
    else:
        if user_date is None:
            st.warning("è«‹è¼¸å…¥æœ‰æ•ˆçš„æŒ‡å®šæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰ã€‚")
            st.stop()
        target_date = user_date
        target_date_str = str(target_date)

    st.info(f"å°‡æ¯”å°çš„ç›®æ¨™æ—¥æœŸï¼š {target_date_str}")

    dfs = extract_tables_to_dfs(doc)
    result_rows = []

    if dfs and prefer_table:
    st.write(f"åµæ¸¬åˆ° {len(dfs)} å€‹è¡¨æ ¼ï¼Œä»¥ä¸‹ç‚ºå„è¡¨æ ¼çš„é è¦½èˆ‡æ¯”å°è¨­å®šï¼š")

    result_rows = []

    for i, df in enumerate(dfs, start=1):
        with st.expander(f"ğŸ“‹ è¡¨æ ¼ {i} é è¦½", expanded=True):
            df = df.astype(str)

            st.dataframe(df.head(50), use_container_width=True)

            # è‡ªå‹•æŠ“å‡ºæ¬„ä½åç¨±
            table_cols = [c for c in df.columns if str(c).strip() != ""]
            if not table_cols:
                st.warning("æ­¤è¡¨æ ¼æ²’æœ‰å¯è¾¨è­˜çš„æ¬„ä½åç¨±ï¼ˆå¯èƒ½ç¼ºå°‘æ¨™é¡Œåˆ—ï¼‰ã€‚")
                continue

            # é è¨­æ‰€æœ‰æ¬„ä½éƒ½å‹¾é¸
            chosen_cols = st.multiselect(
                f"è¡¨æ ¼ {i} â€” é¸æ“‡è¦æ¯”å°çš„æ¬„ä½",
                options=table_cols,
                default=table_cols
            )

            # è‹¥ä½¿ç”¨è€…æ²’æœ‰é¸ä»»ä½•æ¬„ä½å°±è·³é
            if not chosen_cols:
                continue

            # åŸ·è¡Œæ¯”å°
            for col in chosen_cols:
                filtered = filter_df_by_date_in_column(df, col, target_date)
                if not filtered.empty:
                    filtered = filtered.copy()
                    snippets = []
                    for _, r in filtered.iterrows():
                        cell_text = str(r[col])
                        td_candidates = [
                            target_date.strftime("%Y-%m-%d"),
                            target_date.strftime("%Y/%m/%d"),
                            f"{target_date.year}å¹´{target_date.month}æœˆ{target_date.day}æ—¥"
                        ]
                        start_idx = -1
                        chosen_td = None
                        for td in td_candidates:
                            if td in cell_text:
                                start_idx = cell_text.find(td)
                                chosen_td = td
                                break
                        if start_idx != -1:
                            end_idx = min(len(cell_text), start_idx + len(chosen_td) + num_chars)
                            snippet = cell_text[start_idx:end_idx]
                        else:
                            snippet = ""
                        snippets.append(snippet)
                    filtered = filtered.reset_index(drop=True)
                    filtered["text"] = snippets
                    filtered["_source_table"] = f"table_{i}"
                    filtered["_matched_column"] = col
                    filtered = filtered[filtered["text"].str.strip() != ""]
                    if not filtered.empty:
                        result_rows.append(filtered)

    if not result_rows:
        st.write("å¾æ®µè½ä¸­æœå°‹å«æœ‰ç›®æ¨™æ—¥æœŸçš„æ–‡å­—...")
        paragraphs = [p.text.strip() for p in doc.paragraphs if p.text.strip()]
        para_matches = []

        for i, txt in enumerate(paragraphs):
            parsed = find_date_like_in_text(txt)
            if parsed and any(d == target_date for d in parsed):
                td_candidates = [
                    target_date.strftime("%Y-%m-%d"),
                    target_date.strftime("%Y/%m/%d"),
                    f"{target_date.year}å¹´{target_date.month}æœˆ{target_date.day}æ—¥"
                ]
                start_idx = -1
                chosen_td = None
                for td in td_candidates:
                    if td in txt:
                        start_idx = txt.find(td)
                        chosen_td = td
                        break
                if start_idx != -1:
                    end_idx = min(len(txt), start_idx + len(chosen_td) + num_chars)
                    snippet = txt[start_idx:end_idx]
                    para_matches.append((i, snippet))

        if para_matches:
            dfp = pd.DataFrame(para_matches, columns=["para_index", "text"])
            dfp["_source_table"] = "paragraphs"
            dfp["_matched_column"] = "text"
            result_rows.append(dfp)

    if result_rows:
        final = pd.concat(result_rows, ignore_index=True, sort=False)
        final = final[final["text"].astype(str).str.strip() != ""].reset_index(drop=True)

        st.subheader("æ‰¾åˆ°çš„çµæœç¯„ä¾‹ï¼ˆå‰ 200 åˆ—ï¼‰")
        st.dataframe(final.head(200))
        st.write(f"å…±æ‰¾åˆ° {len(final)} ç­†ç¬¦åˆç›®æ¨™æ—¥æœŸ ({target_date_str}) çš„é …ç›®ã€‚")

        if download_format == "CSV":
            towrite = io.StringIO()
            final.to_csv(towrite, index=False, encoding="utf-8-sig")
            st.download_button(
                "ä¸‹è¼‰ CSV æª”ï¼ˆUTF-8-SIGï¼‰",
                data=towrite.getvalue().encode("utf-8-sig"),
                file_name=f"summary_{target_date_str}.csv",
                mime="text/csv"
            )
        elif download_format == "ç´”æ–‡å­— (TXT)":
            txt_buf = io.StringIO()
            for i, row in final.iterrows():
                txt_buf.write(f"ä¾†æº: {row.get('_source_table','')}, æ¬„ä½: {row.get('_matched_column','')}\n")
                txt_buf.write(f"{row.get('text','')}\n")
                txt_buf.write("----\n")
            st.download_button(
                "ä¸‹è¼‰ TXT æª”",
                data=txt_buf.getvalue().encode("utf-8"),
                file_name=f"summary_{target_date_str}.txt",
                mime="text/plain"
            )
        elif download_format == "Word (.docx)":
            export_to_word(final, target_date_str, num_chars, filename="æ—¥æœŸæ®µè½æ‘˜è¦.docx")
            out_doc = docx.Document("æ—¥æœŸæ®µè½æ‘˜è¦.docx")
            word_stream = io.BytesIO()
            out_doc.save(word_stream)
            word_stream.seek(0)
            st.download_button(
                "ä¸‹è¼‰ Word æ‘˜è¦æª”",
                data=word_stream,
                file_name=f"summary_{target_date_str}.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
    else:
        st.warning("æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„é …ç›®ã€‚è«‹ç¢ºèªï¼š\n- Word æ˜¯å¦å«æœ‰è¡¨æ ¼æˆ–æ®µè½ä¸­æ˜¯å¦æœ‰æ—¥æœŸå­—ä¸²ã€‚\n- è‹¥æ—¥æœŸæ ¼å¼ç‰¹æ®Šï¼Œå¯å˜—è©¦æ‰‹å‹•è¼¸å…¥ç²¾ç¢ºæ—¥æœŸå­—ä¸²ä½œç‚ºæ¯”å°æ¢ä»¶ã€‚")



